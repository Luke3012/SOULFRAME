\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

SOULFRAME nasce da un'esigenza molto concreta: in tanti ambienti VR la scena è curata e credibile, ma quando si prova a parlare con l'agente l'esperienza si rompe subito, tra risposte poco coerenti, tempi d'attesa e interazioni macchinose. Questa tesi presenta SOULFRAME, un prototipo di sistema conversazionale con avatar 3D pensato per affrontare il tema della loneliness e, soprattutto, per rendere il dialogo con l'AI più naturale e accessibile: l'utente deve poter parlare senza "smanettare", con un'interfaccia chiara e adatta sia a desktop (tastiera e controlli tradizionali) sia a mobile/touch (push-to-talk e navigazione semplificata).

Il progetto è costruito con una logica client–server: Unity WebGL gestisce avatar, interfaccia e registrazione dell'audio; sul backend una serie di servizi separati si occupa di capire la voce, generare risposte contestuali con supporto di memoria e restituire una voce sintetica credibile. La memoria è legata al singolo avatar e può essere arricchita con note e contenuti esterni (anche documenti e immagini).

Durante lo sviluppo sono emersi punti critici tipici di un sistema end-to-end: integrazione tra componenti, latenza percepita e compatibilità tra ambienti. Per ridurre attriti e errori, ho dato molta importanza anche all'automazione di setup e gestione dei servizi. Il risultato è un prototipo stabile, utilizzabile sia in locale sia su server, che rende chiari i colli di bottiglia e mostra una pipeline vocale davvero impiegabile in scenari realistici.
